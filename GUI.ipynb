{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog, messagebox, ttk\n",
    "import pyaudio\n",
    "import wave\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import librosa\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "import torchvision.models as models\n",
    "from transformers import HubertModel, AutoProcessor\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerFeatureDataset(Dataset):\n",
    "    def __init__(self, pkl_path):\n",
    "        data = pickle.load(open(pkl_path, 'rb'))\n",
    "        self.X = torch.tensor(data['features'], dtype=torch.float32)  \n",
    "        self.y = torch.tensor(data['labels'],   dtype=torch.long)    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]\n",
    "\n",
    "class LayerWeightedAggregator(nn.Module):\n",
    "    def __init__(self, num_layers):\n",
    "        super().__init__()\n",
    "        self.w = nn.Parameter(torch.ones(num_layers) / num_layers)\n",
    "    def forward(self, x):\n",
    "        w = torch.softmax(self.w, dim=0)             \n",
    "        return (x * w[None, :, None]).sum(dim=1)\n",
    "\n",
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self, num_layers, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.agg = LayerWeightedAggregator(num_layers)\n",
    "        H = W = int(np.sqrt(hidden_dim))\n",
    "        assert H*W == hidden_dim, \"hidden_dim must be square\"\n",
    "        self.H, self.W = H, W\n",
    "\n",
    "        self.resnet = models.resnet18(pretrained=True)\n",
    "        self.resnet.conv1 = nn.Conv2d(1,\n",
    "            self.resnet.conv1.out_channels,\n",
    "            kernel_size=self.resnet.conv1.kernel_size,\n",
    "            stride=self.resnet.conv1.stride,\n",
    "            padding=self.resnet.conv1.padding,\n",
    "            bias=False)\n",
    "        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.agg(x)               \n",
    "        b = x.size(0)\n",
    "        x = x.view(b, 1, self.H, self.W)\n",
    "        return self.resnet(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "Sampled Files: ['../ASV/Artifact/LA_E_9464037_clipping.wav', '../ASV/Artifact/LA_E_8206846_filter.wav', '../ASV/Artifact/LA_E_4967785_noise.wav', '../ASV/Artifact/LA_E_6782766_reverb.wav', '../ASV/Data/LA_E_5324584.flac', '../ASV/Artifact/LA_E_5590452_filter.wav', '../ASV/Artifact/LA_E_8964992_clipping.wav', '../ASV/Artifact/LA_E_5986045_compression.wav', '../ASV/Artifact/LA_E_9835790_reverb.wav', '../ASV/Artifact/LA_E_9715080_filter.wav']\n",
      "Sampled Labels: [1, 0, 0, 0, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "pkl_path = \"../Features/Opt_Features/ASV_Opt_Dataset.pkl\"\n",
    "dataset = LayerFeatureDataset(pkl_path)\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/hubert-large-ls960-ft\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = ResNetClassifier(num_layers, hidden_dim, num_classes)\n",
    "model.load_state_dict(torch.load(\"model.pth\"))\n",
    "model.eval()\n",
    "hub = HubertModel.from_pretrained(\"facebook/hubert-large-ls960-ft\", output_hidden_states=True).to(device)\n",
    "hub.eval()\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "num_layers  = dataset.X.size(1)\n",
    "hidden_dim  = dataset.X.size(2)\n",
    "num_classes = len(torch.unique(dataset.y))\n",
    "\n",
    "with open(\"ASV_sample.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "print(\"Sampled Files:\", data[\"files\"])\n",
    "print(\"Sampled Labels:\", data[\"labels\"])\n",
    "\n",
    "audio_files = data[\"files\"]\n",
    "audio_labels = data[\"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(filename):\n",
    "    waveform, sample_rate = torchaudio.load(filename)\n",
    "    waveform = waveform.to(device)\n",
    "    if sample_rate != 16000:\n",
    "        waveform = torchaudio.transforms.Resample(sample_rate, 16000)(waveform)\n",
    "    if waveform.size(0) > 1:\n",
    "        waveform = waveform.mean(dim=0, keepdim=True)\n",
    "    return waveform.squeeze(0)\n",
    "\n",
    "\n",
    "def extract_features(waveform):\n",
    "    with torch.no_grad():\n",
    "        inputs = processor(waveform, sampling_rate=16000, return_tensors=\"pt\").to(device)\n",
    "        outputs = hub(**inputs)\n",
    "        hidden_states = outputs.hidden_states[2:6]  # layers 3rd to 6th\n",
    "        pooled = [hs.mean(dim=1).squeeze(0).cpu().numpy() for hs in hidden_states]\n",
    "        features = np.stack(pooled, axis=0)  \n",
    "        features = torch.tensor(features, dtype=torch.float32)\n",
    "    return features\n",
    "\n",
    "sys.stderr = open(os.devnull, 'w')\n",
    "def play_audio(file_path):\n",
    "    try:\n",
    "        chunk = 1024\n",
    "        wf = wave.open(file_path, 'rb')\n",
    "        p = pyaudio.PyAudio()\n",
    "\n",
    "        # Open stream\n",
    "        stream = p.open(format=p.get_format_from_width(wf.getsampwidth()),\n",
    "                        channels=wf.getnchannels(),\n",
    "                        rate=wf.getframerate(),\n",
    "                        output=True)\n",
    "\n",
    "        # Read data\n",
    "        data = wf.readframes(chunk)\n",
    "\n",
    "        # Play stream\n",
    "        while data:\n",
    "            stream.write(data)\n",
    "            data = wf.readframes(chunk)\n",
    "\n",
    "        # Close everything\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error playing audio: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeAudioApp:\n",
    "    def __init__(self, master):\n",
    "        self.master = master\n",
    "        master.title(\"Fake Audio Detector\")\n",
    "        master.geometry(\"700x450\")              # Larger window\n",
    "        master.configure(bg=\"#f0f0f0\")          # Light gray background\n",
    "\n",
    "        # Use a ttk style\n",
    "        style = ttk.Style(master)\n",
    "        style.theme_use('clam')\n",
    "        style.configure('TLabel', background='#f0f0f0', font=('Helvetica', 12))\n",
    "        style.configure('Header.TLabel', font=('Helvetica', 16, 'bold'))\n",
    "        style.configure('TButton', font=('Helvetica', 12), padding=6)\n",
    "\n",
    "        # Header\n",
    "        header = ttk.Label(master, text=\"Fake Audio Detector\", style='Header.TLabel')\n",
    "        header.pack(pady=(20, 10))\n",
    "\n",
    "        # Frame for controls\n",
    "        controls = ttk.Frame(master, padding=20, style='TFrame')\n",
    "        controls.pack(fill='x', expand=False)\n",
    "\n",
    "        ttk.Label(controls, text=\"Choose a number (1-10):\").grid(row=0, column=0, sticky='w')\n",
    "        self.number_var = tk.StringVar(value=\"1\")\n",
    "        number_menu = ttk.Combobox(controls, textvariable=self.number_var,\n",
    "                                   values=[str(i) for i in range(1,11)],\n",
    "                                   state='readonly', width=5, font=('Helvetica',12))\n",
    "        number_menu.grid(row=0, column=1, padx=(10,0), sticky='w')\n",
    "\n",
    "        btn_frame = ttk.Frame(master, padding=(20,10))\n",
    "        btn_frame.pack(fill='x', expand=False)\n",
    "\n",
    "        self.play_btn = ttk.Button(btn_frame, text=\"► Play\", command=self.play_selected, width=15)\n",
    "        self.play_btn.grid(row=0, column=0, padx=10)\n",
    "\n",
    "        self.classify_btn = ttk.Button(btn_frame, text=\"✔ Classify\", command=self.classify_selected, width=15)\n",
    "        self.classify_btn.grid(row=0, column=1, padx=10)\n",
    "\n",
    "        sep = ttk.Separator(master, orient='horizontal')\n",
    "        sep.pack(fill='x', pady=10)\n",
    "\n",
    "        result_frame = ttk.Frame(master, padding=20)\n",
    "        result_frame.pack(fill='both', expand=True)\n",
    "\n",
    "        ttk.Label(result_frame, text=\"Result:\", font=('Helvetica', 14)).grid(row=0, column=0, sticky='nw')\n",
    "        self.result_lbl = ttk.Label(result_frame, text=\"–\", font=('Helvetica', 24, 'bold'), foreground='#007acc')\n",
    "        self.result_lbl.grid(row=1, column=0, sticky='n')\n",
    "\n",
    "        for child in controls.winfo_children():\n",
    "            child.grid_configure(pady=5)\n",
    "        btn_frame.grid_columnconfigure(0, weight=1)\n",
    "        btn_frame.grid_columnconfigure(1, weight=1)\n",
    "\n",
    "        self.selected_file = None\n",
    "\n",
    "    def play_selected(self):\n",
    "        try:\n",
    "            selected_number = int(self.number_var.get())\n",
    "            self.selected_file = audio_files[selected_number - 1]\n",
    "\n",
    "            play_audio(self.selected_file)\n",
    "        except Exception as e:\n",
    "            print(\"Error\", f\"An error occurred during playback:\\n{e}\")\n",
    "\n",
    "    def classify_selected(self):\n",
    "        try:\n",
    "            selected_number = int(self.number_var.get())\n",
    "            print(\"Selected number:\", selected_number)\n",
    "            self.selected_file = audio_files[selected_number - 1]\n",
    "            print(\"Selected file:\", self.selected_file)\n",
    "            \n",
    "            waveform = load_audio(self.selected_file)\n",
    "            if waveform is None:\n",
    "                return\n",
    "\n",
    "            features = extract_features(waveform)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = model(features)\n",
    "                preds = torch.argmax(outputs, dim=1).item()\n",
    "                label = \"Fake\" if preds == 1 else \"Real\"\n",
    "\n",
    "            self.result_lbl.config(text=f\"Result: {label}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error\", f\"An error occurred during classification:\\n{e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected number: 1\n",
      "Selected file: ../ASV/Artifact/LA_E_9464037_clipping.wav\n",
      "Selected number: 7\n",
      "Selected file: ../ASV/Artifact/LA_E_8964992_clipping.wav\n",
      "Selected number: 10\n",
      "Selected file: ../ASV/Artifact/LA_E_9715080_filter.wav\n",
      "Selected number: 2\n",
      "Selected file: ../ASV/Artifact/LA_E_8206846_filter.wav\n",
      "Selected number: 7\n",
      "Selected file: ../ASV/Artifact/LA_E_8964992_clipping.wav\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = FakeAudioApp(root)\n",
    "    root.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
